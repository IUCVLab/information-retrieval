{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95edd0c6-b44e-40d6-9e9c-48f42ddd5207",
   "metadata": {},
   "source": [
    "# 0. [OPTIONAL] Installing course dependencies\n",
    "\n",
    "These are dependencies for the whole course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae1d575-f278-450f-aa6f-d99e075a79e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158874a2-fb2f-4429-8c13-01457e9767b4",
   "metadata": {},
   "source": [
    "You may skip the next block for now. You will need `ffmpeg` on week 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f337db2-7f6a-4520-b51e-f38f064ed599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda update -y base conda\n",
    "!conda install -c conda-forge ffmpeg -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c2f0dd-1d63-412c-ae93-2f012c3d8f0c",
   "metadata": {},
   "source": [
    "Run the next cell if you want to download embedding model, but this is not required during this lab. You can do it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fa01d2-dd4d-48d4-a27b-9ae610d9e7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_trf_distilbertbaseuncased_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef7bedc-d559-437e-b106-12c860acfbab",
   "metadata": {},
   "source": [
    "# 1. Touching the Internet\n",
    "\n",
    "Solve the following task.\n",
    "1. Download [this page](https://raw.githubusercontent.com/IUCVLab/information-retrieval/main/datasets/facts.txt)\n",
    "2. Save it to the file with the **unique** name derived from the URL. NB File with another URL should not be save into the file with this name. E.g. [this file](https://github.com/IUCVLab/information-retrieval/blob/main/datasets/facts.txt) is another file with another content!\n",
    "\n",
    "Hints:\n",
    "- [requests](https://docs.python-requests.org/en/latest/) library is cool.\n",
    "- [hashlib](https://docs.python.org/3/library/hashlib.html) may help with computing hash strings.\n",
    "- when you download and save the data, don't try to encode and decode it. Use binary format when working with streams and files. <span style=\"color:red\">Discuss with your TA which encodings you know and how they differ</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639fb2d7-d577-4ae6-beb4-2487213024cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url1 = \"https://raw.githubusercontent.com/IUCVLab/information-retrieval/main/datasets/facts.txt\"\n",
    "url2 = \"https://github.com/IUCVLab/information-retrieval/blob/main/datasets/facts.txt\"\n",
    "\n",
    "# TODO: download and save these documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7601aaf-3534-42cd-bb33-665d2d92c79d",
   "metadata": {},
   "source": [
    "# 2. Parsing different formats\n",
    "\n",
    "Most probably, if you meet something in the Internet, this is one of: binary, plain text, XML, or json. XML then splits into xHTML, RSS, Atom, SOAP, XML-RPC, ... . Your task is to learn, how to process different formats.\n",
    "\n",
    "## 2.1. JSON\n",
    "\n",
    "In [the given file](http://sprotasov.ru/data/postnauka.txt) there is valid json. Parse this file and print all video URLs, which have `computer science` tag. Use built-in features of `requests`, or just a `json` library ([ref](https://docs.python.org/3/library/json.html)).\n",
    "\n",
    "Hint:\n",
    "- if the file has issues with parsing read about [the difference](https://stackoverflow.com/questions/57152985/what-is-the-difference-between-utf-8-and-utf-8-sig)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628c2c18-b896-40f9-bac9-2fefc5027da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "url = \"http://sprotasov.ru/data/postnauka.txt\"\n",
    "\n",
    "# TODO. Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97530a0-46d4-47e3-a7bb-ca479680007d",
   "metadata": {},
   "source": [
    "## 2.2. HTML\n",
    "\n",
    "For a given StackExchange answer extract logins of the contributors (who asked and who answered) with votes. [bs4](https://beautiful-soup-4.readthedocs.io/en/latest/) will help you to do the job.\n",
    "\n",
    "I can recommend to use CSS or XPath selectors. `div` elements with `post-layout` class represent answers. Inside there are `div` with `votecell` class stroring votes number and `div` with class `user-details` storing user info. My personal recommendation is to use `css selectors`, which are [documented here](https://beautiful-soup-4.readthedocs.io/en/latest/#css-selectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67db473-a8f0-414c-adbc-ce0e9e4710bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://math.stackexchange.com/questions/411486/\"\\\n",
    "        \"understanding-the-singular-value-decomposition-svd\"\n",
    "print(url)\n",
    "\n",
    "# TODO. Your code here should parse HTML source page and find contributors of the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6708766b-0db3-4062-87a1-9ba96c60440b",
   "metadata": {},
   "source": [
    "# 2.3. RSS feed\n",
    "\n",
    "A lot of information is already organized in typed XML documents. Podcasts, for example, are just RSS feed. Parse [the feed of this podcast](http://sprotasov.ru/podcast/rss.xml) and print out:\n",
    "- the number of episodes\n",
    "- the length of the time span between the first and the last episodes (in days).\n",
    "\n",
    "Use [`feedparser` library for this](https://waylonwalker.com/parsing-rss-python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2090f810-d706-4bb2-8c85-d485a48432a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "rss = 'http://sprotasov.ru/podcast/rss.xml'\n",
    "# feedparser.parse(rss) \n",
    "\n",
    "# TODO: complete the code to compute the time span of all the episodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7a63b1-c106-4a13-8e55-9240e9c8418f",
   "metadata": {},
   "source": [
    "# 3. [EXTRA TASK] Solving simple information retrieval task\n",
    "\n",
    "According to the name, `information retrieval` is the discipline, which helps retrieves information (from unstructured sources). Thus, we will retrieve some information from [this news article](https://www.bbc.com/news/world-us-canada-59944889). Your task is to write a code, which will answer the question: **How many people die every day in the US waiting for a transplant?** Write flexible enough code. Test yourself by changing the link to [this one](https://www.americantransplantfoundation.org/about-transplant/facts-and-myths/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7660c706-371b-4050-aede-e4b3e4014ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'https://www.bbc.com/news/world-us-canada-59944889'\n",
    "url2 = 'https://www.americantransplantfoundation.org/about-transplant/facts-and-myths/'\n",
    "\n",
    "question = 'How many people die every day in the US waiting for a transplant?'\n",
    "\n",
    "# TODO. Impress me!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
